---
created: 2024-02-25 07:44
modified: Sunday 25th February 2024 07:44:45
alias:
---
up::
tags:: #neural-networks
links::
## Activation Function

**Activation Functions** are mathematical operations applied to the sum of the weighted inputs of a neuron. They add non-linearity to the network so it learn more complex patterns in the data.

**Why do we Need a Non-Linear Activation Function in an Artificial Neural Network?**
Without Non-Linearity we cannot approximate a simple XOR function.
We can not draw a linear line to separate the blue and red points. We need a non-linear function.
Linear activation functions like the identify function f(x) = x will result in a linear relationship between the input and output of the neuron, straight lines

![[Screenshot 2024-02-25 at 7.45.53 AM.png|500]]

### Resources
[Activation Functions in Deep Learning - A Complete Overview](https://learnopencv.com/understanding-activation-functions-in-deep-learning/)
[How Neural Networks Solve the XOR Problem | by Aniruddha Karajgi | Towards Data Science](https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7)
